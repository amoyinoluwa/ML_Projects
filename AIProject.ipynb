{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA-rb_kWMO08"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RMJFTT2lU-h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aBFQLVXlayb"
      },
      "source": [
        "https://drive.google.com/drive/u/2/folders/1DQvpn46Zgp2U8mgmaPqAQQ8LGdSz97MS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_5REGW-mpar",
        "outputId": "82b2361f-65bf-44c2-e759-addffc3de60c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Ly4PDwniIM",
        "outputId": "6189e619-f609-4f37-92e6-5da748c61766"
      },
      "source": [
        "%cd /content/gdrive/My Drive/archive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/archive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD1U0JJ6nk0P",
        "outputId": "5c5cdb16-056a-4d3f-d2eb-12b531b21eba"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOY8u0USp7KS"
      },
      "source": [
        "trainDir = '/content/gdrive/My Drive/archive/train'\n",
        "testDir = '/content/gdrive/My Drive/archive/eval'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2CvMYkAnnyx",
        "outputId": "2ebe0e29-6e26-412b-c8f0-99c575d17996"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        validation_split = 0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "trainFiles = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(64, 64),\n",
        "        subset='training',\n",
        "        batch_size=256,\n",
        "        color_mode = 'grayscale',\n",
        "        class_mode='categorical')\n",
        "valFiles = train_datagen.flow_from_directory(\n",
        "        trainDir,\n",
        "        target_size=(64, 64),\n",
        "        subset='validation',\n",
        "        batch_size=256,\n",
        "        color_mode = 'grayscale',\n",
        "        class_mode='categorical')\n",
        "testFiles = test_datagen.flow_from_directory(testDir, target_size=(64, 64),\n",
        "    color_mode = 'grayscale',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6068 images belonging to 16 classes.\n",
            "Found 1509 images belonging to 16 classes.\n",
            "Found 1018 images belonging to 17 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4fCQdHtMF2n",
        "outputId": "cf449ef9-8eea-4f8c-a2b7-c6427ccc2726"
      },
      "source": [
        "class_names = trainFiles.class_indices\n",
        "classes = []\n",
        "for i in class_names.keys():\n",
        "  classes.append(i)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['decimal', 'div', 'eight', 'equal', 'five', 'four', 'minus', 'nine', 'one', 'plus', 'seven', 'six', 'three', 'times', 'two', 'zero']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UvQqTAWlRvJ"
      },
      "source": [
        "#build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,1)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(16, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ0QRfNvLbGc",
        "outputId": "55d7f19b-a77a-4c7c-ecf1-67fef6aa932a"
      },
      "source": [
        "start_time = time.time()\n",
        "trainedModel = model.fit(trainFiles, validation_data=valFiles, epochs=15)\n",
        "print(\"Training completed in %s minutes\" % int((time.time() - start_time)/60.00))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.1503 - accuracy: 0.9542 - val_loss: 0.3772 - val_accuracy: 0.8946\n",
            "Epoch 2/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.1491 - accuracy: 0.9560 - val_loss: 0.3784 - val_accuracy: 0.8993\n",
            "Epoch 3/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.1328 - accuracy: 0.9611 - val_loss: 0.3843 - val_accuracy: 0.8907\n",
            "Epoch 4/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.1233 - accuracy: 0.9647 - val_loss: 0.4062 - val_accuracy: 0.8873\n",
            "Epoch 5/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.1209 - accuracy: 0.9624 - val_loss: 0.3862 - val_accuracy: 0.8933\n",
            "Epoch 6/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.1057 - accuracy: 0.9682 - val_loss: 0.3837 - val_accuracy: 0.8993\n",
            "Epoch 7/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.0871 - accuracy: 0.9738 - val_loss: 0.3701 - val_accuracy: 0.9092\n",
            "Epoch 8/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.0877 - accuracy: 0.9748 - val_loss: 0.3775 - val_accuracy: 0.9066\n",
            "Epoch 9/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.0925 - accuracy: 0.9703 - val_loss: 0.3602 - val_accuracy: 0.9039\n",
            "Epoch 10/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.0825 - accuracy: 0.9756 - val_loss: 0.3906 - val_accuracy: 0.8993\n",
            "Epoch 11/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.0813 - accuracy: 0.9758 - val_loss: 0.4026 - val_accuracy: 0.8973\n",
            "Epoch 12/15\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.0868 - accuracy: 0.9731 - val_loss: 0.4100 - val_accuracy: 0.9013\n",
            "Epoch 13/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.0798 - accuracy: 0.9764 - val_loss: 0.3813 - val_accuracy: 0.8933\n",
            "Epoch 14/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.0700 - accuracy: 0.9797 - val_loss: 0.3776 - val_accuracy: 0.9112\n",
            "Epoch 15/15\n",
            "24/24 [==============================] - 42s 2s/step - loss: 0.0653 - accuracy: 0.9807 - val_loss: 0.3887 - val_accuracy: 0.9006\n",
            "Training completed in 15 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY13JT9WHlkn"
      },
      "source": [
        "#accuracy plot\n",
        "plt.plot(trainedModel.history['accuracy'])\n",
        "plt.plot(trainedModel.history['val_accuracy'])\n",
        "plt.title(\"Training and validation accuracy plot\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}